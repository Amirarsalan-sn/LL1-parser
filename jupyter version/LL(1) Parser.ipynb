{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c67c96",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b088d0",
   "metadata": {},
   "source": [
    "We just need to install pandas and tabulate libraries using pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e68283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b31eeeb",
   "metadata": {},
   "source": [
    "# Important variabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1eb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side = {}\n",
    "right_side = {}\n",
    "first = {}\n",
    "follow = {}\n",
    "RHS = []\n",
    "rules = []\n",
    "predict_set = []\n",
    "non_terminals = set()\n",
    "starting_non_terminal = None\n",
    "terminals = set()\n",
    "parse_table = {}\n",
    "\"\"\"priority is just a map which shows the order of non-terminals that are going to be printed in parse table it does\n",
    "   not have any implementation use \"\"\"\n",
    "priority = {}\n",
    "welcome = \"\"\"Hello!! this is LL(1) parser speaking, in order to parse your grammar you need to observe some rules :\n",
    "1) In order to show the result of a production rule use -> .\n",
    "2) Non-terminals should be uppercase letters,\n",
    "   And terminals should be lowercase or other combinations of symbols (except -> and $ and | and micro).\n",
    "3) Epsilon can be represented by \"\" . \n",
    "4) The first non-terminal of the first production rule will be assumed as the starting non-terminal.\n",
    "5) Insert space after tokens you type and obviously type each production rule in a single line .\n",
    "6) If you're done typing the grammar don't panic, just simply type done in the next line .\n",
    "7) If your grammar was not LL(1) you will be informed.\n",
    "8) DO NOT USE \"\" UNLESS FOR NULL PRODUCTION RULES LIKE D -> \"\" . \n",
    "An example of a valid grammar : \n",
    "E -> E + E | E * E\n",
    "E -> id\n",
    "done\n",
    "\n",
    "Ok so you now know the rules and you even saw a valid example, that was it. READY? SET, GO! :\"\"\"\n",
    "\n",
    "rule_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e499e3",
   "metadata": {},
   "source": [
    "Left_side is a dictionary from a non-terminal to the index of all rules which that non-terminal is in the left side of the rule.\n",
    "For example : "
   ]
  },
  {
   "cell_type": "raw",
   "id": "914e47e8",
   "metadata": {},
   "source": [
    "(0) E -> A B d\n",
    "(1) A -> a + v\n",
    "(2) E -> \"\"\n",
    "(3) B -> a b c\n",
    "(4) B -> c B A\n",
    "=> left_side[E] = [0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770b53f",
   "metadata": {},
   "source": [
    "Right_side is a dictionary from a non-terminal to a list of tuples. First index of these tuples indicates the rule index which a non-terminal has appeared in the right side that rule and, The second index indicates its position"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43f289e0",
   "metadata": {},
   "source": [
    "right_side[A] = [(0, 0), (4, 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba855df",
   "metadata": {},
   "source": [
    "First is a dictionary from a non-terminal to its first set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ec5be",
   "metadata": {},
   "source": [
    "Follow is a dictionary from a non-terminal to its follow set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef029e3d",
   "metadata": {},
   "source": [
    "Predict_set[i] is assosiated with rules[i]. It shows the set of first terminals that this production rule can lead to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb0d8c2",
   "metadata": {},
   "source": [
    "Parse_table is a dictionary of dictionary :). The first level key is a non-terminal and the second level key is a terminal. It shows with non-terminal(for example E) and terminal(For example +) what rule(Or rules, In case of not LL(1) grammars) I can use. (Operates exactly like a table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead05ba",
   "metadata": {},
   "source": [
    "## Important functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8617ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_grammar(string):\n",
    "    global rule_index\n",
    "    global starting_non_terminal\n",
    "    split = string.split()\n",
    "    rhs_i = []\n",
    "    last_l = 2\n",
    "    non_terminal = split[0]\n",
    "    if non_terminal.islower():\n",
    "        print(f\"You were supposed to enter uppercase letter as non-terminal :/\")\n",
    "        exit(0)\n",
    "    if rule_index == 0:\n",
    "        starting_non_terminal = non_terminal\n",
    "    non_terminals.add(non_terminal)\n",
    "    priority[non_terminal] = rule_index\n",
    "    rules_i = [non_terminal, \"->\"]\n",
    "    for i in range(2, len(split)):\n",
    "        if split[i].isupper():\n",
    "            rhs_i.insert(0, split[i])\n",
    "            rules_i.append(split[i])\n",
    "            non_terminals.add(split[i])\n",
    "            if split[i] in right_side:\n",
    "                right_side[split[i]].add((rule_index, i - last_l))\n",
    "            else:\n",
    "                right_side[split[i]] = {(rule_index, i - last_l)}\n",
    "        elif split[i].islower():\n",
    "            if split[i] == \"micro\":\n",
    "                print(f\"I said don't use micro as a terminal :/ don't believe me? then what is this:\\n{split}\")\n",
    "                exit(0)\n",
    "            if i - last_l != 0:\n",
    "                rhs_i.insert(0, \"micro\")\n",
    "                rhs_i.insert(0, split[i])\n",
    "            else:\n",
    "                rhs_i.insert(0, split[i])\n",
    "            terminals.add(split[i])\n",
    "            rules_i.append(split[i])\n",
    "        elif split[i] == \"|\":\n",
    "            if i - last_l == 0:\n",
    "                print(f\"One of your grammars were wrong : \\n{split}\\nWhy did you use | at the start of your rule ??:/\")\n",
    "                exit(0)\n",
    "            else:\n",
    "                RHS.append(rhs_i)\n",
    "                rules.append(rules_i)\n",
    "                if non_terminal in left_side:\n",
    "                    left_side[non_terminal].add(rule_index)\n",
    "                else:\n",
    "                    left_side[non_terminal] = {rule_index}\n",
    "                rules_i = [non_terminal, \"->\"]\n",
    "                rhs_i = []\n",
    "                rule_index = rule_index + 1\n",
    "                last_l = i + 1\n",
    "        elif split[i] == \"->\":\n",
    "            print(f\"I said don't use -> as a terminal :/ don't believe me? then what is this:\\n{split}\")\n",
    "            exit(0)\n",
    "        elif split[i] == \"$\":\n",
    "            print(f\"I said don't use $ as a terminal :/ don't believe me? then what is this:\\n{split}\")\n",
    "            exit(0)\n",
    "        else:\n",
    "            if i - last_l != 0:\n",
    "                rhs_i.insert(0, \"micro\")\n",
    "                rhs_i.insert(0, split[i])\n",
    "            else:\n",
    "                if split[i] != '\"\"':\n",
    "                    rhs_i.insert(0, split[i])\n",
    "            if split[i] != '\"\"':\n",
    "                terminals.add(split[i])\n",
    "            rules_i.append(split[i])\n",
    "    RHS.append(rhs_i)\n",
    "    rules.append(rules_i)\n",
    "    if non_terminal in left_side:\n",
    "        left_side[non_terminal].add(rule_index)\n",
    "    else:\n",
    "        left_side[non_terminal] = {rule_index}\n",
    "    rule_index = rule_index + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b28a5",
   "metadata": {},
   "source": [
    "This function extracts information from given grammar. It creates RHS of every rule and inserts that RHS in the RHS[ ]. It constructs information inside left_side, right_side, terminals, non_terminals, starting_non_terminal, rules[ ], RHS[ ]. Also this function detects and reports some possible errors caused by user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3439daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_first(non_terminal):\n",
    "    global update\n",
    "    before = first[non_terminal].copy()\n",
    "    for l_pos in left_side[non_terminal]:\n",
    "        if rules[l_pos][2] in terminals or rules[l_pos][2] == '\"\"':\n",
    "            first[non_terminal].add(rules[l_pos][2])\n",
    "        else:\n",
    "            for i in range(2, len(rules[l_pos])):\n",
    "                if rules[l_pos][i] in terminals:\n",
    "                    first[non_terminal].add(rules[l_pos][i])\n",
    "                    break\n",
    "                u_set = first[rules[l_pos][i]].copy()\n",
    "                if '\"\"' in u_set:\n",
    "                    if i != len(rules[l_pos]) - 1:\n",
    "                        u_set.remove('\"\"')\n",
    "                    first[non_terminal].update(u_set)\n",
    "                else:\n",
    "                    first[non_terminal].update(u_set)\n",
    "                    break\n",
    "    if before != first[non_terminal]:\n",
    "        update = True\n",
    "\n",
    "\n",
    "def update_follow(non_terminal):\n",
    "    global update\n",
    "    before = follow[non_terminal].copy()\n",
    "    if non_terminal not in right_side:\n",
    "        return\n",
    "    for r_pos in right_side[non_terminal]:\n",
    "        rule = rules[r_pos[0]]\n",
    "        if r_pos[1] + 2 == len(rule) - 1:\n",
    "            follow[non_terminal].update(follow[rule[0]])\n",
    "        else:\n",
    "            for i in range(r_pos[1] + 3, len(rule)):\n",
    "                if rule[i] in terminals:\n",
    "                    follow[non_terminal].add(rule[i])\n",
    "                    break\n",
    "                u_set = first[rule[i]].copy()\n",
    "                if '\"\"' in u_set:\n",
    "                    u_set.remove('\"\"')\n",
    "                    follow[non_terminal].update(u_set)\n",
    "                    if i == len(rule) - 1:\n",
    "                        follow[non_terminal].update(follow[rule[0]])\n",
    "                else:\n",
    "                    follow[non_terminal].update(u_set)\n",
    "                    break\n",
    "    if before != follow[non_terminal]:\n",
    "        update = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1a42e",
   "metadata": {},
   "source": [
    "Update_first() and update_follow() help us finding the first set and follow set of a non-terminal 'with out' using recursive calls. So that if the grammar had left-recursion (indirect or direct) the program can still find first and follow sets with no need to elliminating left_recurtions and leaves the production rules untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952b8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_useless(non_terminal):\n",
    "    if non_terminal not in left_side:\n",
    "        return True\n",
    "    if (non_terminal not in right_side) and T != starting_non_terminal:\n",
    "        return True\n",
    "    for i in left_side[T]:\n",
    "        if T not in RHS[i]:\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea8058",
   "metadata": {},
   "source": [
    "This function can tell you whether a non-terminal is a useless one or not. If I want to give some explanation about how this function works I will simply show you some examples:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b8f091b",
   "metadata": {},
   "source": [
    "(1) S -> A B C\n",
    "(2) C -> id | e f C\n",
    "(3) B -> B + B | e * B | f - e - B\n",
    "(4) D -> id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69240a",
   "metadata": {},
   "source": [
    "As you can see A is useless (Gets trapped into the first if statement). D is usless (Gets trapped into the second if statement). Also, B is useless. Wonder why ? Take a look at rules[3], Yes, It never ends :) (Passes the trapes but can't make it through the for loop). If a non_terminal is not useless then it's useful (S ,C). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531566be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index):\n",
    "    rule = rules[index]\n",
    "    index_predict_set = set()\n",
    "    for i in range(2, len(rule)):\n",
    "        if rule[i] in terminals:\n",
    "            index_predict_set.add(rule[i])\n",
    "            break\n",
    "        if rule[i] == '\"\"':\n",
    "            index_predict_set.update(follow[rule[0]])\n",
    "            break\n",
    "        u_set = first[rule[i]].copy()\n",
    "        if '\"\"' in first[rule[i]]:\n",
    "            u_set.remove('\"\"')\n",
    "            index_predict_set.update(u_set)\n",
    "            if i == len(rule) - 1:\n",
    "                index_predict_set.update(follow[rule[0]])\n",
    "        else:\n",
    "            index_predict_set.update(u_set)\n",
    "            break\n",
    "    predict_set.insert(index, index_predict_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b660726",
   "metadata": {},
   "source": [
    "This function constructs the predict_set for a specified rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e84ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_parse_table():\n",
    "    is_ll1 = True\n",
    "    for nt in non_terminals:\n",
    "        parse_table[nt] = {}\n",
    "\n",
    "    for t in terminals:\n",
    "        for nt in non_terminals:\n",
    "            for i in left_side[nt]:\n",
    "                if t in predict_set[i]:\n",
    "                    if t in parse_table[nt]:\n",
    "                        is_ll1 = False\n",
    "                    else:\n",
    "                        parse_table[nt][t] = []\n",
    "                    parse_table[nt][t].append(i)\n",
    "            if t not in parse_table[nt]:\n",
    "                parse_table[nt][t] = [-1]\n",
    "    return is_ll1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef192eda",
   "metadata": {},
   "source": [
    "Construct_parse_table() constructs the parse table and decides if the input grammar is LL(1) or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947dfecc",
   "metadata": {},
   "source": [
    "# Main flow of program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dcb67f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!! this is LL(1) parser speaking, in order to parse your grammar you need to observe some rules :\n",
      "1) In order to show the result of a production rule use -> .\n",
      "2) Non-terminals should be uppercase letters,\n",
      "   And terminals should be lowercase or other combinations of symbols (except -> and $ and | and micro).\n",
      "3) Epsilon can be represented by \"\" . \n",
      "4) The first non-terminal of the first production rule will be assumed as the starting non-terminal.\n",
      "5) Insert space after tokens you type and obviously type each production rule in a single line .\n",
      "6) If you're done typing the grammar don't panic, just simply type done in the next line .\n",
      "7) If your grammar was not LL(1) you will be informed.\n",
      "8) DO NOT USE \"\" UNLESS FOR NULL PRODUCTION RULES LIKE D -> \"\" . \n",
      "An example of a valid grammar : \n",
      "E -> E + E | E * E\n",
      "E -> id\n",
      "done\n",
      "\n",
      "Ok so you now know the rules and you even saw a valid example, that was it. READY? SET, GO! :\n",
      "E -> T E'\n",
      "E' -> + T E' | \"\"\n",
      "T -> F T'\n",
      "T' -> * F T' | \"\"\n",
      "F -> id\n",
      "F -> ( E )\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(welcome)\n",
    "comm = input()\n",
    "\n",
    "while comm != \"done\":\n",
    "    extract_grammar(comm)\n",
    "    comm = input()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43ee1c",
   "metadata": {},
   "source": [
    "After receiving the grammar, It is time for some initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "924e468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for T in non_terminals:\n",
    "    first[T] = set()\n",
    "    follow[T] = set()\n",
    "\n",
    "follow[starting_non_terminal].add(\"$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b906d",
   "metadata": {},
   "source": [
    "Now, Let's check if there is any useless non-terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1127da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for T in non_terminals:\n",
    "    if is_useless(T):\n",
    "        print(f\"\"\"You have a useless non-terminal ({T}), that doesn't mean that your grammar is not LL(1) but it's \n",
    "better to enter a grammar with all non-terminals being, useful so I'll quite processing your grammar :)\"\"\")\n",
    "        exit(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7d3fc",
   "metadata": {},
   "source": [
    "Then, First and follow sets for any non-terminals is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5efcb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = True\n",
    "while update:\n",
    "    update = False\n",
    "    for T in non_terminals:\n",
    "        update_first(T)\n",
    "update = True\n",
    "while update:\n",
    "    update = False\n",
    "    for T in non_terminals:\n",
    "        update_follow(T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f73c9",
   "metadata": {},
   "source": [
    "This is how we can find first and follow with out being conserned about left recursions or any other special cases. This algorithm will update first and follow for every non-terminal until no changes occur in those sets. Then, We can claim we have found first and follow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c04c75",
   "metadata": {},
   "source": [
    "After finding first and follow, It is time to finally construct parse table and create DataFrames using pandas from does tables and dictionaries and arrays ... in order to print them into programs terminal using tabulate. This part will also inform you if the input grammar wasn't LL(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee4b015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════╤════════════════════╕\n",
      "│    │ Production Rules   │\n",
      "╞════╪════════════════════╡\n",
      "│  0 │ E -> T E'          │\n",
      "├────┼────────────────────┤\n",
      "│  1 │ E' -> + T E'       │\n",
      "├────┼────────────────────┤\n",
      "│  2 │ E' -> \"\"           │\n",
      "├────┼────────────────────┤\n",
      "│  3 │ T -> F T'          │\n",
      "├────┼────────────────────┤\n",
      "│  4 │ T' -> * F T'       │\n",
      "├────┼────────────────────┤\n",
      "│  5 │ T' -> \"\"           │\n",
      "├────┼────────────────────┤\n",
      "│  6 │ F -> id            │\n",
      "├────┼────────────────────┤\n",
      "│  7 │ F -> ( E )         │\n",
      "╘════╧════════════════════╛\n",
      "\n",
      "nullable/first/follow table:\n",
      "\n",
      "╒════╤════════════╤═════════╤══════════╕\n",
      "│    │ nullable   │ first   │ follow   │\n",
      "╞════╪════════════╪═════════╪══════════╡\n",
      "│ E  │ N          │ id (    │ $ )      │\n",
      "├────┼────────────┼─────────┼──────────┤\n",
      "│ E' │ Y          │ \"\" +    │ $ )      │\n",
      "├────┼────────────┼─────────┼──────────┤\n",
      "│ T  │ N          │ id (    │ $ + )    │\n",
      "├────┼────────────┼─────────┼──────────┤\n",
      "│ T' │ Y          │ \"\" *    │ $ + )    │\n",
      "├────┼────────────┼─────────┼──────────┤\n",
      "│ F  │ N          │ id (    │ $ + ) *  │\n",
      "╘════╧════════════╧═════════╧══════════╛\n",
      "\n",
      "And this is the parse table:\n",
      "\n",
      "╒════╤═════╤═════╤══════╤═════╤═════╤═════╕\n",
      "│    │   + │   ) │   id │   ( │   * │   $ │\n",
      "╞════╪═════╪═════╪══════╪═════╪═════╪═════╡\n",
      "│ E  │  -1 │  -1 │    0 │   0 │  -1 │  -1 │\n",
      "├────┼─────┼─────┼──────┼─────┼─────┼─────┤\n",
      "│ E' │   1 │   2 │   -1 │  -1 │  -1 │   2 │\n",
      "├────┼─────┼─────┼──────┼─────┼─────┼─────┤\n",
      "│ T  │  -1 │  -1 │    3 │   3 │  -1 │  -1 │\n",
      "├────┼─────┼─────┼──────┼─────┼─────┼─────┤\n",
      "│ T' │   5 │   5 │   -1 │  -1 │   4 │   5 │\n",
      "├────┼─────┼─────┼──────┼─────┼─────┼─────┤\n",
      "│ F  │  -1 │  -1 │    6 │   7 │  -1 │  -1 │\n",
      "╘════╧═════╧═════╧══════╧═════╧═════╧═════╛\n",
      "\n",
      "╒════╤═════════════╕\n",
      "│    │ RHS         │\n",
      "╞════╪═════════════╡\n",
      "│  0 │ E' T        │\n",
      "├────┼─────────────┤\n",
      "│  1 │ E' T +      │\n",
      "├────┼─────────────┤\n",
      "│  2 │             │\n",
      "├────┼─────────────┤\n",
      "│  3 │ T' F        │\n",
      "├────┼─────────────┤\n",
      "│  4 │ T' F *      │\n",
      "├────┼─────────────┤\n",
      "│  5 │             │\n",
      "├────┼─────────────┤\n",
      "│  6 │ id          │\n",
      "├────┼─────────────┤\n",
      "│  7 │ ) micro E ( │\n",
      "╘════╧═════════════╛\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(rules)):\n",
    "    predict(j)\n",
    "terminals.add(\"$\")\n",
    "ll1 = construct_parse_table()\n",
    "terminals.remove(\"$\")\n",
    "terminals_list = list(terminals)\n",
    "\"just want to put the '$' at the end of the list which going to be printed in parse table\"\n",
    "terminals_list.append(\"$\")\n",
    "non_terminals_list = list(non_terminals)\n",
    "\"now we should sort the non-terminals-list in for parse table\"\n",
    "for j in range(len(non_terminals_list)):\n",
    "    min_p = priority[non_terminals_list[j]]\n",
    "    min_i = j\n",
    "    for k in range(j + 1, len(non_terminals_list)):\n",
    "        if priority[non_terminals_list[k]] < min_p:\n",
    "            min_p = priority[non_terminals_list[k]]\n",
    "            min_i = k\n",
    "    temp = non_terminals_list[j]\n",
    "    non_terminals_list[j] = non_terminals_list[min_i]\n",
    "    non_terminals_list[min_i] = temp\n",
    "\"this section creates data frame of nullable , first, and follow for each non-terminal\"\n",
    "f_f_n_for_show = {\"nullable\": [],\n",
    "                  \"first\": [],\n",
    "                  \"follow\": []}\n",
    "for ntr in non_terminals_list:\n",
    "    if '\"\"' in first[ntr]:\n",
    "        f_f_n_for_show[\"nullable\"].append(\"Y\")\n",
    "    else:\n",
    "        f_f_n_for_show[\"nullable\"].append(\"N\")\n",
    "    f_f_n_for_show[\"first\"].append(' '.join(first[ntr]))\n",
    "    f_f_n_for_show[\"follow\"].append(' '.join(follow[ntr]))\n",
    "f_f_n_for_show[\"nullable\"] = pd.Series(f_f_n_for_show[\"nullable\"], index=non_terminals_list)\n",
    "f_f_n_for_show[\"first\"] = pd.Series(f_f_n_for_show[\"first\"], index=non_terminals_list)\n",
    "f_f_n_for_show[\"follow\"] = pd.Series(f_f_n_for_show[\"follow\"], index=non_terminals_list)\n",
    "\n",
    "f_f_n_df = pd.DataFrame(f_f_n_for_show)\n",
    "\"this section creates data frame of rules and RHS\"\n",
    "rules_for_show = {\"Production Rules\": pd.Series(' '.join(e) for e in rules)}\n",
    "RHS_for_show = {\"RHS\": pd.Series(' '.join(e) for e in RHS)}\n",
    "\n",
    "rules_df = pd.DataFrame(rules_for_show)\n",
    "RHS_df = pd.DataFrame(RHS_for_show)\n",
    "\n",
    "\"this section creates data frame of parse table\"\n",
    "parse_table_for_show = {}\n",
    "for tr in terminals_list:\n",
    "    data = []\n",
    "    for ntr in non_terminals_list:\n",
    "        data.append(' '.join(str(e) for e in parse_table[ntr][tr]))\n",
    "    parse_table_for_show[tr] = pd.Series(data, index=non_terminals_list)\n",
    "\n",
    "parse_table_df = pd.DataFrame(parse_table_for_show)\n",
    "\n",
    "\n",
    "\"\"\"this section is the print section, first the rules will be printed then the nullable ,first ,follow table after \n",
    "that parse table will be printed and at last RHS \"\"\"\n",
    "print(f\"{tabulate(rules_df, headers='keys', tablefmt='fancy_grid')}\\n\")\n",
    "print(f\"\"\"nullable/first/follow table:\n",
    "\n",
    "{tabulate(f_f_n_df, headers='keys', tablefmt='fancy_grid')}\\n\"\"\")\n",
    "print(f\"\"\"And this is the parse table:\n",
    "\n",
    "{tabulate(parse_table_df, headers='keys', tablefmt='fancy_grid')}\\n\"\"\")\n",
    "print(f\"{tabulate(RHS_df, headers='keys', tablefmt='fancy_grid')}\\n\")\n",
    "if not ll1:\n",
    "    print(\"GRAMMAR IS NOT LL(1)\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d28b98",
   "metadata": {},
   "source": [
    "Bellow, is the parser code. Parser code will parse a given input string and it'll print the result step by step. You can also give orders to parser code after each step. Orders like n(next step), r(reset), e(exit).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da3f9c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you can enter a string for me to parse, After entering the string the parse stack will be printed \n",
      "after each step and then you should enter one of tree letters(r/n/e) r means restart which restarts the \n",
      "process, n will show you the next step and e will terminate the process. if you wanted to finish the parser at \n",
      "'entering string' level type exit\n",
      "Enter the string (don't forget to put space between):\n",
      "id + id\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E           │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ id + id $          │\n",
      "╘════════════════════╛\n",
      "╒════════╕\n",
      "│ rule   │\n",
      "╞════════╡\n",
      "╘════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E' T        │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ id + id $          │\n",
      "╘════════════════════╛\n",
      "╒═══════════╕\n",
      "│ rule      │\n",
      "╞═══════════╡\n",
      "│ E -> T E' │\n",
      "╘═══════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E' T' F     │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ id + id $          │\n",
      "╘════════════════════╛\n",
      "╒═══════════╕\n",
      "│ rule      │\n",
      "╞═══════════╡\n",
      "│ T -> F T' │\n",
      "╘═══════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E' T' id    │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ id + id $          │\n",
      "╘════════════════════╛\n",
      "╒═════════╕\n",
      "│ rule    │\n",
      "╞═════════╡\n",
      "│ F -> id │\n",
      "╘═════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E' T'       │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ + id $             │\n",
      "╘════════════════════╛\n",
      "╒═════════════╕\n",
      "│ rule        │\n",
      "╞═════════════╡\n",
      "│ matching id │\n",
      "╘═════════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E'          │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ + id $             │\n",
      "╘════════════════════╛\n",
      "╒══════════╕\n",
      "│ rule     │\n",
      "╞══════════╡\n",
      "│ T' -> \"\" │\n",
      "╘══════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E' T +      │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ + id $             │\n",
      "╘════════════════════╛\n",
      "╒══════════════╕\n",
      "│ rule         │\n",
      "╞══════════════╡\n",
      "│ E' -> + T E' │\n",
      "╘══════════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E' T        │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ id $               │\n",
      "╘════════════════════╛\n",
      "╒════════════╕\n",
      "│ rule       │\n",
      "╞════════════╡\n",
      "│ matching + │\n",
      "╘════════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E' T' F     │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ id $               │\n",
      "╘════════════════════╛\n",
      "╒═══════════╕\n",
      "│ rule      │\n",
      "╞═══════════╡\n",
      "│ T -> F T' │\n",
      "╘═══════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E' T' id    │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ id $               │\n",
      "╘════════════════════╛\n",
      "╒═════════╕\n",
      "│ rule    │\n",
      "╞═════════╡\n",
      "│ F -> id │\n",
      "╘═════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E' T'       │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ $                  │\n",
      "╘════════════════════╛\n",
      "╒═════════════╕\n",
      "│ rule        │\n",
      "╞═════════════╡\n",
      "│ matching id │\n",
      "╘═════════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $ E'          │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ $                  │\n",
      "╘════════════════════╛\n",
      "╒══════════╕\n",
      "│ rule     │\n",
      "╞══════════╡\n",
      "│ T' -> \"\" │\n",
      "╘══════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│ $             │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│ $                  │\n",
      "╘════════════════════╛\n",
      "╒══════════╕\n",
      "│ rule     │\n",
      "╞══════════╡\n",
      "│ E' -> \"\" │\n",
      "╘══════════╛\n",
      "command : n\n",
      "╒═══════════════╕\n",
      "│ parse stack   │\n",
      "╞═══════════════╡\n",
      "│               │\n",
      "╘═══════════════╛\n",
      "╒════════════════════╕\n",
      "│ remaining string   │\n",
      "╞════════════════════╡\n",
      "│                    │\n",
      "╘════════════════════╛\n",
      "╒════════════════════════════════════╕\n",
      "│ rule                               │\n",
      "╞════════════════════════════════════╡\n",
      "│ finished parsing (string accepted) │\n",
      "╘════════════════════════════════════╛\n",
      "Enter the string (don't forget to put space between):\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Now you can enter a string for me to parse, After entering the string the parse stack will be printed \n",
    "after each step and then you should enter one of tree letters(r/n/e) r means restart which restarts the \n",
    "process, n will show you the next step and e will terminate the process. if you wanted to finish the parser at \n",
    "'entering string' level type exit\"\"\")\n",
    "while True:\n",
    "    Error = False\n",
    "    finished = False\n",
    "    string_to_parse = input(\"Enter the string (don't forget to put space between):\\n\")\n",
    "    if string_to_parse == 'exit':\n",
    "        break\n",
    "    string_to_parse = string_to_parse.split()\n",
    "    string_to_parse.append(\"$\")\n",
    "    stack = ['$', starting_non_terminal]\n",
    "    parse_stack = [[\"parse stack\"], [' '.join(stack)]]\n",
    "    remaining_string = [[\"remaining string\"], [' '.join(string_to_parse)]]\n",
    "    current_rule = [[\"rule\"], []]\n",
    "    print(tabulate(parse_stack, headers='firstrow', tablefmt='fancy_grid'))\n",
    "    print(tabulate(remaining_string, headers='firstrow', tablefmt='fancy_grid'))\n",
    "    print(tabulate(current_rule, headers='firstrow', tablefmt='fancy_grid'))\n",
    "    pointer = 0\n",
    "    while True:\n",
    "        comm = input(\"command : \")\n",
    "        if comm == 'r':\n",
    "            break\n",
    "        if comm == 'e':\n",
    "            print(\"See you later\")\n",
    "            exit(0)\n",
    "        top = stack[-1]\n",
    "        if top in terminals:\n",
    "            pointer = pointer + 1\n",
    "            stack.pop()\n",
    "            parse_stack[1] = [' '.join(stack)]\n",
    "            remaining_string[1] = [' '.join(string_to_parse[s] for s in range(pointer, len(string_to_parse)))]\n",
    "            current_rule[1] = [f\"matching {top}\"]\n",
    "        elif top in non_terminals:\n",
    "            if string_to_parse[pointer] in terminals or string_to_parse[pointer] == \"$\":\n",
    "                parse_pointer = parse_table[top][string_to_parse[pointer]][0]\n",
    "                stack.pop()\n",
    "                if parse_pointer != -1:\n",
    "                    stack.extend(RHS[parse_pointer])\n",
    "                    parse_stack[1] = [' '.join(stack)]\n",
    "                    current_rule[1] = [' '.join(rules[parse_pointer])]\n",
    "                else:\n",
    "                    Error = True\n",
    "                    current_rule[1] = [f\"There is no rule which can lead non-terminal {top} to terminal {string_to_parse[pointer]} (string not accepted)\"]\n",
    "            else:\n",
    "                Error = True\n",
    "                current_rule[1] = [f\"Word {string_to_parse[pointer]} is not a terminal (string not accepted)\"]\n",
    "        elif top == \"micro\":\n",
    "            stack.pop()\n",
    "            if stack[-1] != string_to_parse[pointer]:\n",
    "                Error = True\n",
    "                current_rule[1] = [f\"Expected {stack[-1]}, got {string_to_parse[pointer]} instead (string not accepted)\"]\n",
    "            else:\n",
    "                pointer = pointer+1\n",
    "                match = stack.pop()\n",
    "                parse_stack[1] = [' '.join(stack)]\n",
    "                remaining_string[1] = [' '.join(string_to_parse[s] for s in range(pointer, len(string_to_parse)))]\n",
    "                current_rule[1] = [f\"matching {match}\"]\n",
    "        elif top == \"$\":\n",
    "            if top == string_to_parse[pointer]:\n",
    "                pointer = pointer + 1\n",
    "                stack.pop()\n",
    "                parse_stack[1] = [' '.join(stack)]\n",
    "                remaining_string[1] = [' '.join(string_to_parse[s] for s in range(pointer, len(string_to_parse)))]\n",
    "                current_rule[1] = [f\"finished parsing (string accepted)\"]\n",
    "                finished = True\n",
    "            else:\n",
    "                Error = True\n",
    "                current_rule[1] = [f\"Expected {top}, got {string_to_parse[pointer]} instead (string not accepted)\"]\n",
    "        if Error:\n",
    "            finished = True\n",
    "        print(tabulate(parse_stack, headers='firstrow', tablefmt='fancy_grid'))\n",
    "        print(tabulate(remaining_string, headers='firstrow', tablefmt='fancy_grid'))\n",
    "        print(tabulate(current_rule, headers='firstrow', tablefmt='fancy_grid'))\n",
    "        if finished:\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
